# Spread Spain â€” Amazon Product Monitor Backend

## What's Included

```
spread-spain-backend/
â”œâ”€â”€ app.py          â† Flask REST API server (main entry point)
â”œâ”€â”€ scraper.py      â† Playwright + BeautifulSoup Amazon scraper
â”œâ”€â”€ database.py     â† SQLite setup & connection helper
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py        â† One-click installer
â”œâ”€â”€ dashboard.html  â† Frontend (open in browser)
â””â”€â”€ README.md
```

---

## Quick Start (5 minutes)

### Step 1 â€” Install Python
Download Python 3.10â€“3.13 from https://python.org  
âœ… During install: check **"Add Python to PATH"**  
âš ï¸  Python 3.14 works but is very new â€” 3.12 or 3.13 recommended.

### Step 2 â€” Open a Command Prompt in the backend folder
Right-click the `spread-spain-backend` folder â†’ **"Open in Terminal"**  
(or open Command Prompt and `cd` to the folder)

> âš ï¸ **Do NOT run setup.py by double-clicking** â€” that opens `pythonw.exe` which can't install packages.  
> Always run from a **Command Prompt / Terminal**.

### Step 3 â€” Run Setup (one time only)
```
python setup.py
```
This will:
- Create a `venv` virtual environment
- Install all packages inside it
- Download the Chromium browser for scraping
- Create `START_SERVER.bat` for easy startup

### Step 4 â€” Start the Server
**Option A:** Double-click `START_SERVER.bat`  

**Option B:** Command Prompt:
```
venv\Scripts\python app.py
```

You'll see:
```
ğŸš€ Spread Spain Backend starting on http://localhost:5000
ğŸ“… Auto-scrape scheduled every 6 hours
```

### Step 5 â€” Open the Dashboard
Open `dashboard.html` in your browser.  
The green **BACKEND ONLINE** badge confirms the connection.

---

## API Reference

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET  | `/api/health`              | Check server is running |
| GET  | `/api/products`            | Get all monitored products |
| POST | `/api/products`            | Add & scrape a single product |
| DELETE | `/api/products/<url>`    | Remove a product |
| POST | `/api/products/bulk`       | Add multiple URLs (background) |
| POST | `/api/products/refresh`    | Re-scrape all products |
| POST | `/api/products/refresh-one`| Re-scrape one product |
| GET  | `/api/history?url=...`     | Price/rating history |
| GET  | `/api/stats`               | Summary stats |
| GET  | `/api/scheduler`           | Scheduler status |
| POST | `/api/scheduler`           | Change scrape interval |

### Example â€” Add a product
```bash
curl -X POST http://localhost:5000/api/products \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.amazon.in/dp/B0EXAMPLE"}'
```

### Example â€” Change auto-scrape to every 2 hours
```bash
curl -X POST http://localhost:5000/api/scheduler \
  -H "Content-Type: application/json" \
  -d '{"hours": 2}'
```

---

## Features

### ğŸ•·ï¸ Scraper
- Real Playwright browser (Chromium) â€” handles JavaScript-rendered pages
- Anti-bot measures: randomised user agents, realistic headers, homepage warmup
- Extracts: title, price, MRP, rating, reviews, BSR rank, stock status, image
- Auto-retry on failure (up to 3 attempts)
- Detects CAPTCHA and logs it

### ğŸ—„ï¸ Database (SQLite â€” no setup required)
- `products` table: all product data
- `history` table: price/rating/rank snapshots over time
- Stored at `products.db` in the same folder

### â° Scheduler
- Default: every 6 hours
- Changeable from the dashboard dropdown (30 min â†’ 24 hr)
- Runs in background â€” server stays responsive

### ğŸŒ REST API
- CORS enabled â€” works with the frontend on any port
- All responses are JSON

---

## Troubleshooting

**"Backend offline" banner shows**  
â†’ Make sure `python app.py` is running in your terminal

**Scrape returns no data**  
â†’ Amazon shows CAPTCHA â€” wait 10 minutes, try a different product first  
â†’ Check your internet connection  
â†’ Make sure Playwright Chromium installed: `python -m playwright install chromium`

**Port 5000 already in use**  
â†’ Change the port at the bottom of `app.py`:  
`app.run(host="0.0.0.0", port=5001, debug=False)`  
â†’ Also update the `API` variable in `dashboard.html`:  
`const API = "http://localhost:5001/api";`

**Slow scraping**  
â†’ Amazon scraping takes 5â€“15 seconds per product  
â†’ Bulk imports run in background â€” dismiss the progress bar and check back

---

## Notes on Amazon Scraping
- Amazon actively fights scrapers. Large batches may trigger temporary blocks.
- For best results: keep under 50 products refreshing at once
- The 6-hour schedule is intentionally conservative to avoid bans
- Data is for internal monitoring only (Spread Spain's own products)
